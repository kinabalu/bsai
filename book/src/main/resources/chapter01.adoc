= Introduction
:chapter: 1

## Choosing an LLM Implementation

Ollama vs OpenAI (and things like it, like Perplexity)

OpenAI is "better" because it relies on much better hardware, but costs more money, especially when writing a book or running lots of tests that use LLMs.

Ollama gives you access to more models, is free outside of the resource requirements of running it (and you probably have your hardware already) - but those requirements aren't trivial. It's also likely to be, as noted, MUCH less responsive. It's gonna be way slower, in all likelihood. That may not suit your needs.

Ollama also may not support some functionality that services like OpenAI provide, like function calls.

WARNING: need to check this claim about function calls, Joe, or Andrew!

== Next Steps

In our next chapter, ...