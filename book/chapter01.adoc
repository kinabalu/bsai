= Introduction
:chapter: 1

Welcome to Beginning Spring AI!

"Spring AI" refers to a suite of libraries within the Spring Framework designed to help programmers harness some of the most popular artificial intelligence (AI) technologies available today.

In this book, we'll take you on a guided tour of these libraries and their features.
Our goal is not to provide a comprehensive reference on every feature but to offer enough information so you can see the potential of these technologies and use the majority of what you find most valuable.

NOTE: This chapter does not contain code.
It lays a foundational understanding of AI, providing key definitions and concepts, as well as an overview of the technologies covered in this book.
If you prefer diving right into the code, feel free to skip ahead to Chapter 2. However, we suggest revisiting this chapter later on, as it contains valuable insights that will enhance your understanding.

== AI is Everywhere

It's nearly impossible to browse the internet today without encountering AI in some form.
Whether it's writing prompts on Quora, creating visual arts or music, AI is being applied across numerous domains.
There are even entire songs generated by AI that some may find quite respectable.

For programmers, most IDEs now come with AI integrations, suggesting code completions and improvements.
With the right prompts, it's possible to have an AI generate substantial portions of a working application, causing some managers to wonder if they even need human engineers anymorefootnote:[Spoiler alert: yes, the managers do need human engineers. We'll get to why soon, some in this chapter and some in Chapter 6.].

Authors also feel the impact of AI "writing." Many tools now suggest grammar and spelling corrections, as well as more nuanced changes, to evoke a specific tone or style.
AI can even write stories, and when given detailed prompts, the results can sometimes pass for human-written content.

NOTE: It's worth noting for the record: this book has indeed been impacted by AI, and we'll point out why and how later.
We promise.
At least, that's what the AI said to say.
Or did it write it?
Sometimes it's hard to tellfootnote:[This is intended to be humor. If an AI generates any actual content of note in this book, we'll be pointing it out, even if it's not obvious. With that said, when we say AI is used in many writing tools, we mean it; a lot of our grammar was checked and occasionally fixed by AI. It's also worth noting that not even _one_ of the footnotes was suggested by an AI.].

This raises an important question: are humans being replaced by machines?
If AI can create applications, music, or stories that rival human quality, then why do we need humans at all?
There are several compelling answers to this, and some less convincing ones as well.

== What _is_ AI, really?

Let's start by clarifying what AI is.
"Artificial intelligence" is a broad term with numerous applications, and we certainly won't cover all—or even most—of them in this book.

Here's how an AI summarized artificial intelligence:

[source,text]
----
Artificial Intelligence (AI) refers to the development
of computer systems that can perform tasks that normally
require human intelligence, such as learning, problem-solving,
and understanding language. At its core, AI uses mathematical
models to make decisions and predictions—ranging from
simpler approaches like Markov chains, which predict
sequences of events, to more complex systems like recommender
algorithms that suggest movies or products based on user
preferences. With advancements in AI, more sophisticated models
like Large Language Models (LLMs) have emerged, allowing
systems to understand and generate human-like text. These
models can be integrated into applications, such as those
built with Spring AI, to automate and enhance various
tasks across industries.
----

Not bad, ChatGPT!
This example demonstrates a "good use" of AI: providing a _generally_ concise and relevant summary on a topic.
The prompt used here asked for a brief description of AI's evolution, focusing on widely adopted technologies like Large Language Models (LLMs), which we'll explore further in this book.

In the end, it's all literally math, as the paragraph suggested: an input is reduced to a series of numbers, and the AI ... does something with those numbers (what it does depends on the type of AI and its purpose).
It then generates _more_ numbers, and those numbers map to an output - and that applies to nearly every AI model, including the one that generated that paragraph.

Some of the earliest uses of AI models - early enough that some might scoff at the reference to them as "artificial intelligence" - were for tasks like weather prediction or making simple probabilistic decisions.

One simple modeling type is the Markov chain, for example, which is a model that generates a likely outcome based on a string of inputs.
This is actually fairly useful in predicting weather with few variables, and that's actually how it worked.

Consider: if it's raining today, what's the likelihood of it raining _tomorrow?_ If it was raining _yesterday_, does that change the likelihood of rain at all?
What if it's been raining heavily for a week?
Consider also the history of the region being predicted; if it rains every day in June, for example, and it's June, _and_ it's been raining every day so far, can rain tomorrow be predicted?
A Markov chain reduces the history to a series of tokens (which might combine the day of the year, the region, and the weather for that day) and have a set of outcomes that says "95% of the time, when the prior condition looks like _this_, the next day will look like _that_."

Markov chains are also useful for generating text; the ELIZA programfootnote:[An example of ELIZA can be found at `https://web.njit.edu/~ronkowit/eliza.html` . Try it! It's fun! beware: it might make you think of your mother.] emulates a therapist similar to Carl Rogers, by taking significant parts of what you say to it and repeating those parts back to you, in a few different combinations.

Markov chains work on Bayesian probabilities internally; Bayesian algorithms found a lot of use in early attempts to filter email spam, to quite a bit of success, although obviously spammers have found ways to avoid easy detection.

If probabilities don't sound like "artificial intelligence," well, that's fine, but it's generally unfair.
Probabilities rule much of our lives; when we go for a drive, we look at our fuel and calculate how likely it is that we'll need to purchase more, or when, or whether we'll need to take an umbrella or a coat, after all.

AI also has a sort of "magic appeal" in how difficult it can be to understand what's going on behind an invocation.
In the end, it's all math, but ... _what_ math?
And if it's math, well, do we _need_ AI?

The answer is, as you might suspect, "it depends." "What math?" is answered by another question: "What are you trying to do?" An LLM does a lot of stemming and tokenization to reduce a prompt to a series of numbers, which generates some amusing outcomes sometimesfootnote:[A few weeks ago as of this writing, it was a meme about AI that the LLMs couldn't tell how many occurrences of the letter "R" were in the word "strawberry." To us, it's obviously three; to the LLM, however, it was counting based on the tokenized version of the word, which had two Rs, not three, and it ended up looking hopelessly confused, even when corrected.].
A Markov chain gauged towards weather would have _no_ sensible output to an input that asked what `1+1` was - it's simply too sensitive to its problem domain.

It's also important to keep in mind that the reason we have so many models and definitions is because there are so many applications, some appropriate and some not.

It's an aphorism that "when all you have is a hammer, everything looks like a nail." As of this writing, this feels like an accusation; it's rather common to see "can we throw an AI at it?" as a response to problems that, honestly, don't need all that much computation power.

A logistics company might throw artificial intelligence at predicting whether a given package will be late or not - when the answer can be predicted almost as well by simply asking what the weather is like at the destination of the package.
This is a poor application of the resources and power of AI.

That's not to say that you shouldn't use artificial intelligence, at all: it's more an observation that AI is a tool, and like most tools, it has appropriate uses and can be overused, and given the current enthusiasm around a term that few seem to understand, is *often* overused.

== The Scope of This Book

This book primarily focuses on Large Language Models and how to access them with the Spring Framework.

Large language models use a number of techniques to reduce textual prompts to mathematical models, and apply *other* mathematical models to generate responses, also generally textual in nature, although chapters 4 and 5 will show you how to feed audio and visual information into an LLM, and get audio and visual information *out*.

== How can LLMs be used?

LLMs are effectively information blenders; you give them a filter (the prompt) and they generate a probabilistic outcome based on the information on which they were trained.

Therefore, selecting a model can be of critical importance.
(You wouldn't want to use a model trained primarily on fantasy literature to make medical conclusionsfootnote:[You probably wouldn't want to rely on an LLM's medical conclusion even if it were trained on medical data, actually; you'd want an actual competent doctor to make decisions, possibly factoring in observations by an LLM.])

One way to think about the output of an LLM is as if it were selected at random based on what other people _might_ have said, as if the LLM were to take all of the possible answers to your prompt, stir them together and pick elements at random, and then present the result in a cohesive manner.

This is why stories written by an AI tend to be faintly familiar: they are!
They're taking common elements of storytelling and replacing bits as they go, and the result can feel original at times while feeling horribly derivative at other times.
That doesn't mean the story isn't worth telling - most stories in human history have a similar set of concepts at their hearts, as Joseph Campbellfootnote:[Joseph Campbell wrote a book in 1949 called "The Hero with a Thousand Faces," that described a common set of concepts in human mythology, often summed up as the "Hero's Journey." See `https://www.amazon.com/Thousand-Faces-Collected-Joseph-Campbell/dp/1577315936` for more.] might have told you - but it also isn't the same as coming up with "original content."

But with this observation - that LLMs are stirring up knowledge we already had in possibly unexpected ways to come up with content - it's worth saying that this is _useful_.
Sometimes things we want to know are "hiding in plain sight," obscured by tradition and expectation, and an LLM doesn't have the burden of prior knowledge; it can see common patterns that humans can overlook, and without models being specifically limited in what they can observe, an LLM is able to point out that the emperor's not wearing any clothes fairly easily.

For this book, ChatGPT was used as the AI of choice, and it was _also_ used to evaluate content and tone.
Unless specifically pointed out, the words you are reading were written by an actual human person, and were evaluated by an AI to suggest revisions and additions, some of which were accepted.

== How do you choose an LLM?

That's a good question!
As with others, the answer is "it depends on what you want," combined with what you want to spend and the cost of using a given LLM.

There are a lot of choices: ChatGPT (from OpenAI), Meta (from Facebook), Grok (from X), Amazon Bedrock, Claude, and Ollama, and that's just a *few* of the options.
Most of them use a similar API endpoint (after all, they do have a pretty common usage pattern), but their capabilities aren't quite the same; Ollama, for example, as of this writing doesn't support audio or image generation in and of itself, while ChatGPT certainly does.

This is actually why you'd want to use Spring AI: it abstracts much of the low-level APIs into a common framework.
There are areas in which you *are* coding to a specific LLM, particularly when setting the options for how it generates content, but that's *usually* it, and those features can often be set by configuration rather than being set specifically in code.

As far as choosing an LLM: this book primarily focuses on using ChatGPT, because it was one of the first major vendors for AI services using an LLM, and it's remarkably sufficient for a general-purpose AI without being absurdly expensive.
Ollama has the benefit of running locally, if you have a sufficient GPU; it can run without a GPU, in CPU mode, but tends to result in _very_ slow response times.

With that said, the main way to make a decision about which LLM to use is to _try them_ for your purpose.

Work out your application's purpose, write tests that submit to your AI of choice, and see how it performs against other LLMs, and balance the response time and cost against your needs.

== How much does it actually cost?

The popular LLMs (apart from Ollama, which runs locally, and thus is "free" outside of the cost of the hardware used to run it) have various pricing models.
They're typically based on the amount of power it requires to process various prompts and types of prompts, so generating images might have a different cost based on image size and the complexity of the prompt, while text prompts only deal with the complexity of the prompt and its answer.

in addition the the prompts, the models used for processing have their own costs, so a high-quality, large model from a provider is likely to cost more than a simple, fast model from the same provider.
There are lots of providers, each with their own pricing model, so you should take a little time and look at the requirements you have: the pricing model for OpenAI, the host of ChatGPT and the service used most often in this book, has a pricing model that can be found at `https://openai.com/api/pricing/`.

This book uses a lot of very short AI prompts, generally, so the token counts for the entire book, added together, work out to probably under a thousand tokensfootnote:[This is a guess. We could calculate it, because interactions with an LLM include token counts in the response metadata, but given that the total cost for the book would have been under a dollar if the subscription cost didn't cover the required resources, it's just not worth the effort. Your mileage may vary.].
If you run the entire book's tests over and over again, that adds up, but it's still not a lot.

If you're doing a lot of detailed analysis covering a lot of data, your token counts will be higher, and you might run into costs associated with analysis; Chapter 3 covers some ways to mitigate this, but in the end, if you need a certain number of tokens to achieve a task, you... need a certain number of tokens to achieve a task, and your selection of a model and provider will be balanced against your requirements.

The short version of all of that: expect a relatively minor subscription cost, and watch your typical usage to try to predict whether you need additional capacity or not.
If you do need more capacity, consider whether you have the resources to run Ollama locally (meaning that you have a decent GPU and RAM, and a fast disk), and _try it_.

The advantage of external AI providers is that they have massive server farms to throw at tasks, meaning that you can work with larger models and expect faster response times, with more features; the disadvantages of external providers is that they can see your prompts (and how that's used is up to the provider; read the fine print!) and you have to pay for their services.

== What This Book Isn't

This book is going to cover a lot of code, of course, being a book about Spring AI.
However, it presumes you know Java to some degree, and have some familiarity with the Spring Framework (and Spring Boot) already.

It requires you to have Java and Maven installed, although handy links will be provided just in case you don'tfootnote:[Your authors have no idea why books on programming have to walk through basic things like "installing your language of choice," but if you don't have some of that, the technical reviewers whine about it.].

This book does *not* require an IDE.
You'll want one, we think, but ... which one?
We don't know, and don't care.
You can use a simple text editor, if that's what you desire, or IDEA, or Eclipse, or NetBeans, or Visual Studio Code; we offer these names as they occurred to us to write, not as an indication of preference in any way.

The book also generally focuses on tests as a way to demonstrate technique.
There are a few places where there's an application to execute (particularly in Chapter 4, which provides a web-based application to convert text to speech) but the _primary_ demonstration is in setting expectations of output given a specific set of inputs, and validation of that output.

When the code compiles and the tests pass, the code works.
Otherwise, there's not a lot to demonstrate, so there aren't a lot of screenshots to look for.
(Given the nature of probabilistic outputs from LLMs, though, there are places where you might be expected to look at a generated string to make sure it fits your expectations, although we're generally trying to avoid this.)

It's also not a book that's exhaustively going to cover every AI technique - or even every possibility of how to work with a given LLM.
It's focused on large language models, and other techniques are more advanced topics than the topics at which this book is targetedfootnote:[Honest truth: your author considered having an AI rewrite that sentence.].

LLMs have different capabilities and settings; part of why we chose ChatGPT was because ChatGPT covers the features that most people want, and other LLMs may or may not provide the same set of features, but few other LLMs provide features ChatGPT does _not_.
Readers who wish to use alternatives should be able to fine-tune the example code for their specific AI implementation without too much effort.
(And if it takes a lot of effort, feel free to reach out to your authors; we're very interested in helping the industry move forward!)

We're also not covering exhaustive techniques in terms of how the LLMs are being interacted with.
LLMs are conversational processes, and while we _will_ be covering "conversations," we're not going into streaming techniques, that have the LLMs feed back information _as it's being generated_ - this is useful for emulating human behavior ("See, it's typing right now!") but complicates the interactions drastically, and complicated code tends to hide the intent behind what the code is doing.

== Next Steps

In our next chapter, we're going to walk through setting up a project that includes calling ChatGPT through Spring AIfootnote:[It would not be difficult to use any other LLM provider, but again, this book uses ChatGPT, because it's very common, well known, and very predictable - and it definitely provides all of the services the book covers.].
